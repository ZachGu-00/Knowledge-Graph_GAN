"""
é«˜çº§æŽ¨ç†ç³»ç»Ÿï¼šç”Ÿæˆ-ç­›é€‰ (Generate-and-Filter) æ¡†æž¶

åœºæ™¯äºŒï¼šåŒé‡ä¿éšœæŽ¨ç†ç³»ç»Ÿ
- Discoverer (ç”Ÿæˆå™¨): "å¹¿æ’’ç½‘ï¼Œæ‰¾å¥½é±¼" - ç”ŸæˆTop-Kå€™é€‰è·¯å¾„
- Ranker (åˆ¤åˆ«å™¨): "ç²¾æŒ‘ç»†é€‰ï¼Œæ‰¾é±¼çŽ‹" - ä¸ºæ¯æ¡è·¯å¾„æ‰“å‡ºä¸“ä¸šåˆ†æ•°

ä¼˜åŠ¿ï¼š
1. åŒé‡ä¿éšœï¼Œæå‡ç²¾åº¦ï¼šä¸¤é˜¶æ®µéªŒè¯æœºåˆ¶æ˜¾è‘—æå‡Hits@1
2. ç½®ä¿¡åº¦åˆ†æ•°ï¼šRankerè¾“å‡ºå¯é çš„confidence score (0-1)
3. ç³»ç»Ÿé²æ£’æ€§ï¼šRankerèƒ½è¯†åˆ«Discovererçš„é”™è¯¯åˆ¤æ–­
"""

import sys
import torch
import json
import numpy as np
from typing import List, Tuple, Dict, Set, Optional
from pathlib import Path
from datetime import datetime

# æ·»åŠ modelsè·¯å¾„
sys.path.append(str(Path(__file__).parent / "models" / "path_discover"))
sys.path.append(str(Path(__file__).parent / "models" / "path_ranker"))

from differentiable_path_generator_truly_fixed import DifferentiablePathGeneratorTrulyFixed
from enhanced_path_ranker import EnhancedPathRankerDiscriminator
from gan_rl_trainer import GANRLTrainer

class AdvancedInferenceSystem:
    """
    é«˜çº§æŽ¨ç†ç³»ç»Ÿï¼šåŒé‡ä¿éšœçš„è·¯å¾„æŽ¨ç†
    
    æ ¸å¿ƒæ€æƒ³ï¼š
    1. è®­ç»ƒå¥½çš„Discoverer = "è·¯å¾„å‘çŽ°ä¸“å®¶"
    2. è®­ç»ƒå¥½çš„Ranker = "è·¯å¾„é‰´èµå¤§å¸ˆ" 
    3. ä¸¤è€…é…åˆ = æ— æ•Œç»„åˆ
    """
    
    def __init__(self, models_dir: str = "checkpoints/production_models"):
        self.models_dir = Path(models_dir)
        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'
        
        self.discoverer = None  # ç”Ÿæˆå™¨ï¼šè·¯å¾„å‘çŽ°ä¸“å®¶
        self.ranker = None      # åˆ¤åˆ«å™¨ï¼šè·¯å¾„é‰´èµå¤§å¸ˆ
        
        # æŽ¨ç†ç»Ÿè®¡
        self.inference_stats = {
            'total_queries': 0,
            'successful_queries': 0,
            'average_candidates': 0,
            'average_confidence': 0,
            'confidence_distribution': []
        }
    
    def load_production_models(self):
        """
        åŠ è½½ç”Ÿäº§çŽ¯å¢ƒæ¨¡åž‹
        
        é¢„æœŸç»“æž„ï¼š
        checkpoints/production_models/
        â”œâ”€â”€ discoverer_model.pt      # å•ç‹¬çš„ç”Ÿæˆå™¨æƒé‡
        â”œâ”€â”€ ranker_model.pt          # å•ç‹¬çš„åˆ¤åˆ«å™¨æƒé‡
        â”œâ”€â”€ model_metadata.json      # æ¨¡åž‹å…ƒä¿¡æ¯
        â””â”€â”€ training_history.json    # è®­ç»ƒåŽ†å²
        """
        print(f\"Loading production models from: {self.models_dir}\")\n        
        if not self.models_dir.exists():
            print(f\"âŒ Models directory not found: {self.models_dir}\")\n            return False\n        \n        try:\n            # 1. åŠ è½½Discoverer (ç”Ÿæˆå™¨)\n            discoverer_path = self.models_dir / \"discoverer_model.pt\"\n            if discoverer_path.exists():\n                self.discoverer = DifferentiablePathGeneratorTrulyFixed(\n                    entity_embedding_path=\"embeddings/entity_embeddings.pt\",\n                    max_path_length=6,\n                    beam_width=5\n                )\n                self.discoverer.load_state_dict(torch.load(discoverer_path, map_location=self.device))\n                self.discoverer.to(self.device)\n                self.discoverer.eval()\n                print(\"âœ… Discoverer (ç”Ÿæˆå™¨) loaded successfully\")\n            else:\n                print(f\"âŒ Discoverer model not found: {discoverer_path}\")\n                return False\n            \n            # 2. åŠ è½½Ranker (åˆ¤åˆ«å™¨)\n            ranker_path = self.models_dir / \"ranker_model.pt\"\n            if ranker_path.exists():\n                self.ranker = EnhancedPathRankerDiscriminator(\n                    freeze_sbert=True,\n                    disable_pattern_memory=True\n                )\n                self.ranker.load_state_dict(torch.load(ranker_path, map_location=self.device))\n                self.ranker.to(self.device)\n                self.ranker.eval()\n                print(\"âœ… Ranker (åˆ¤åˆ«å™¨) loaded successfully\")\n            else:\n                print(f\"âŒ Ranker model not found: {ranker_path}\")\n                return False\n            \n            # 3. åŠ è½½æ¨¡åž‹å…ƒä¿¡æ¯\n            metadata_path = self.models_dir / \"model_metadata.json\"\n            if metadata_path.exists():\n                with open(metadata_path, 'r', encoding='utf-8') as f:\n                    metadata = json.load(f)\n                print(f\"ðŸ“‹ Model Info: {metadata.get('description', 'N/A')}\")\n                print(f\"ðŸ“… Training Date: {metadata.get('training_date', 'N/A')}\")\n                print(f\"ðŸ† Performance: Hits@1={metadata.get('hits_at_1', 'N/A')}\")\n            \n            print(\"ðŸŽ‰ Production models loaded successfully!\")\n            return True\n            \n        except Exception as e:\n            print(f\"âŒ Error loading models: {e}\")\n            return False\n    \n    def generate_candidate_paths(self, question: str, start_entity: str, \n                               target_entities: Set[str], top_k: int = 5) -> List[Tuple[List[str], float]]:\n        \"\"\"\n        é˜¶æ®µ1ï¼šç”Ÿæˆå€™é€‰è·¯å¾„ (Discovererçš„å·¥ä½œ)\n        \n        Args:\n            question: ç”¨æˆ·é—®é¢˜\n            start_entity: èµ·å§‹å®žä½“\n            target_entities: ç›®æ ‡å®žä½“é›†åˆ\n            top_k: ç”Ÿæˆå€™é€‰æ•°é‡\n            \n        Returns:\n            List of (path, generator_score) tuples\n        \"\"\"\n        if self.discoverer is None:\n            raise ValueError(\"Discoverer not loaded. Call load_production_models() first.\")\n        \n        print(f\"ðŸ” Discoverer: Generating {top_k} candidate paths...\")\n        \n        try:\n            # ä½¿ç”¨ç¡®å®šæ€§æ¨¡å¼ç”Ÿæˆå¤šæ¡è·¯å¾„\n            self.discoverer.eval()\n            generated_paths = self.discoverer.generate_paths(\n                question=question,\n                start_entity=start_entity,\n                target_entities=target_entities,\n                max_paths=top_k,\n                stochastic=False  # ç¡®å®šæ€§ï¼Œä½†ä»èƒ½ç”Ÿæˆå¤šæ ·åŒ–è·¯å¾„\n            )\n            \n            candidates = []\n            for path, score, _ in generated_paths:\n                if len(path) > 0:\n                    candidates.append((path, float(score)))\n            \n            print(f\"âœ… Generated {len(candidates)} candidate paths\")\n            return candidates\n            \n        except Exception as e:\n            print(f\"âŒ Discoverer error: {e}\")\n            return []\n    \n    def rank_and_filter_paths(self, question: str, candidates: List[Tuple[List[str], float]]) -> List[Tuple[List[str], float, float]]:\n        \"\"\"\n        é˜¶æ®µ2ï¼šç­›é€‰ä¸Žé‡æŽ’ (Rankerçš„å·¥ä½œ)\n        \n        Args:\n            question: ç”¨æˆ·é—®é¢˜\n            candidates: [(path, generator_score), ...]\n            \n        Returns:\n            List of (path, generator_score, ranker_confidence) tuplesï¼ŒæŒ‰rankeråˆ†æ•°é™åºæŽ’åˆ—\n        \"\"\"\n        if self.ranker is None:\n            raise ValueError(\"Ranker not loaded. Call load_production_models() first.\")\n        \n        if not candidates:\n            return []\n        \n        print(f\"ðŸ§  Ranker: Evaluating {len(candidates)} candidates...\")\n        \n        try:\n            ranked_results = []\n            \n            for path, gen_score in candidates:\n                # æž„é€ Rankerè¾“å…¥æ ¼å¼\n                final_entity = path[-1]\n                path_string = '.'.join(path)\n                path_data = [{'paths': {final_entity: [path_string]}}]\n                \n                # Rankerè¯„åˆ†\n                with torch.no_grad():\n                    ranker_output = self.ranker([question], path_data, epoch=0)\n                    raw_score = float(ranker_output[0]['individual_scores'][0])\n                    confidence = float(torch.sigmoid(torch.tensor(raw_score)))  # è½¬ä¸º0-1ç½®ä¿¡åº¦\n                \n                ranked_results.append((path, gen_score, confidence))\n            \n            # æŒ‰Rankerç½®ä¿¡åº¦é™åºæŽ’åº\n            ranked_results.sort(key=lambda x: x[2], reverse=True)\n            \n            print(f\"âœ… Ranker evaluation completed\")\n            return ranked_results\n            \n        except Exception as e:\n            print(f\"âŒ Ranker error: {e}\")\n            return [(path, gen_score, 0.0) for path, gen_score in candidates]\n    \n    def inference(self, question: str, start_entity: str, target_entities: Set[str],\n                 top_k_candidates: int = 5, return_all_candidates: bool = False) -> Dict:\n        \"\"\"\n        å®Œæ•´æŽ¨ç†æµç¨‹ï¼šç”Ÿæˆ-ç­›é€‰ (Generate-and-Filter)\n        \n        Args:\n            question: ç”¨æˆ·é—®é¢˜\n            start_entity: èµ·å§‹å®žä½“  \n            target_entities: ç›®æ ‡å®žä½“é›†åˆ\n            top_k_candidates: ç”Ÿæˆå€™é€‰æ•°é‡\n            return_all_candidates: æ˜¯å¦è¿”å›žæ‰€æœ‰å€™é€‰è·¯å¾„\n            \n        Returns:\n            {\n                'best_path': List[str],           # æœ€ä½³è·¯å¾„\n                'confidence': float,              # ç½®ä¿¡åº¦ (0-1)\n                'generator_score': float,         # ç”Ÿæˆå™¨åˆ†æ•°\n                'all_candidates': List,           # æ‰€æœ‰å€™é€‰ï¼ˆå¯é€‰ï¼‰\n                'num_candidates': int,            # å€™é€‰æ•°é‡\n                'inference_time': float           # æŽ¨ç†è€—æ—¶\n            }\n        \"\"\"\n        start_time = datetime.now()\n        \n        print(f\"\\nðŸŽ¯ Advanced Inference: {question}\")\n        print(f\"ðŸ“ Start: {start_entity}\")\n        print(f\"ðŸŽ¯ Targets: {list(target_entities)}\")\n        print(\"-\" * 60)\n        \n        # é˜¶æ®µ1ï¼šDiscovererç”Ÿæˆå€™é€‰\n        candidates = self.generate_candidate_paths(\n            question, start_entity, target_entities, top_k_candidates\n        )\n        \n        if not candidates:\n            return {\n                'best_path': [],\n                'confidence': 0.0,\n                'generator_score': 0.0,\n                'all_candidates': [],\n                'num_candidates': 0,\n                'inference_time': (datetime.now() - start_time).total_seconds(),\n                'status': 'no_candidates_generated'\n            }\n        \n        # é˜¶æ®µ2ï¼šRankerç­›é€‰é‡æŽ’\n        ranked_candidates = self.rank_and_filter_paths(question, candidates)\n        \n        # é€‰æ‹©æœ€ä½³è·¯å¾„ï¼ˆRankeråˆ†æ•°æœ€é«˜çš„ï¼‰\n        best_path, best_gen_score, best_confidence = ranked_candidates[0]\n        \n        # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯\n        self.inference_stats['total_queries'] += 1\n        if best_confidence > 0.5:  # å‡è®¾ç½®ä¿¡åº¦>0.5ä¸ºæˆåŠŸ\n            self.inference_stats['successful_queries'] += 1\n        self.inference_stats['confidence_distribution'].append(best_confidence)\n        \n        inference_time = (datetime.now() - start_time).total_seconds()\n        \n        print(f\"\\nðŸ† FINAL RESULT:\")\n        print(f\"ðŸ“ Best Path: {' -> '.join(best_path)}\")\n        print(f\"ðŸŽ¯ Target Hit: {'YES' if best_path[-1] in target_entities else 'NO'}\")\n        print(f\"ðŸ“Š Generator Score: {best_gen_score:.4f}\")\n        print(f\"ðŸ§  Ranker Confidence: {best_confidence:.4f} ({best_confidence*100:.1f}%)\")\n        print(f\"â±ï¸ Inference Time: {inference_time:.3f}s\")\n        \n        result = {\n            'best_path': best_path,\n            'confidence': best_confidence,\n            'generator_score': best_gen_score,\n            'num_candidates': len(candidates),\n            'inference_time': inference_time,\n            'target_hit': best_path[-1] in target_entities if best_path else False,\n            'status': 'success'\n        }\n        \n        if return_all_candidates:\n            result['all_candidates'] = [\n                {\n                    'path': path,\n                    'generator_score': gen_score,\n                    'ranker_confidence': confidence,\n                    'rank': i + 1\n                }\n                for i, (path, gen_score, confidence) in enumerate(ranked_candidates)\n            ]\n        \n        return result\n    \n    def batch_inference(self, queries: List[Dict], top_k: int = 5) -> List[Dict]:\n        \"\"\"\n        æ‰¹é‡æŽ¨ç†\n        \n        Args:\n            queries: [{'question': str, 'start_entity': str, 'target_entities': Set[str]}, ...]\n            \n        Returns:\n            List of inference results\n        \"\"\"\n        print(f\"\\nðŸš€ Batch Inference: {len(queries)} queries\")\n        print(\"=\" * 80)\n        \n        results = []\n        for i, query in enumerate(queries, 1):\n            print(f\"\\n[{i}/{len(queries)}] Processing query...\")\n            \n            result = self.inference(\n                question=query['question'],\n                start_entity=query['start_entity'],\n                target_entities=query['target_entities'],\n                top_k_candidates=top_k\n            )\n            \n            results.append(result)\n        \n        # æ‰¹é‡ç»Ÿè®¡\n        successful = sum(1 for r in results if r['target_hit'])\n        avg_confidence = np.mean([r['confidence'] for r in results])\n        \n        print(f\"\\nðŸ“Š BATCH RESULTS:\")\n        print(f\"âœ… Success Rate: {successful}/{len(queries)} ({successful/len(queries)*100:.1f}%)\")\n        print(f\"ðŸ§  Average Confidence: {avg_confidence:.4f} ({avg_confidence*100:.1f}%)\")\n        \n        return results\n    \n    def get_system_stats(self) -> Dict:\n        \"\"\"èŽ·å–ç³»ç»Ÿç»Ÿè®¡ä¿¡æ¯\"\"\"\n        if self.inference_stats['total_queries'] == 0:\n            return {'message': 'No inference performed yet'}\n        \n        confidences = self.inference_stats['confidence_distribution']\n        \n        return {\n            'total_queries': self.inference_stats['total_queries'],\n            'success_rate': self.inference_stats['successful_queries'] / self.inference_stats['total_queries'],\n            'average_confidence': np.mean(confidences),\n            'confidence_std': np.std(confidences),\n            'confidence_distribution': {\n                'high (>0.8)': sum(1 for c in confidences if c > 0.8),\n                'medium (0.5-0.8)': sum(1 for c in confidences if 0.5 < c <= 0.8),\n                'low (<0.5)': sum(1 for c in confidences if c <= 0.5)\n            }\n        }\n\ndef save_production_models(gan_trainer: GANRLTrainer, models_dir: str = \"checkpoints/production_models\"):\n    \"\"\"\n    å°†è®­ç»ƒå¥½çš„GAN-RLæ¨¡åž‹ä¿å­˜ä¸ºç”Ÿäº§çŽ¯å¢ƒæ ¼å¼\n    \n    ä¿å­˜ç»“æž„ï¼š\n    checkpoints/production_models/\n    â”œâ”€â”€ discoverer_model.pt      # ç”Ÿæˆå™¨æƒé‡\n    â”œâ”€â”€ ranker_model.pt          # åˆ¤åˆ«å™¨æƒé‡  \n    â”œâ”€â”€ model_metadata.json      # å…ƒä¿¡æ¯\n    â””â”€â”€ training_history.json    # è®­ç»ƒåŽ†å²\n    \"\"\"\n    models_path = Path(models_dir)\n    models_path.mkdir(parents=True, exist_ok=True)\n    \n    print(f\"ðŸ’¾ Saving production models to: {models_path}\")\n    \n    # 1. ä¿å­˜ç”Ÿæˆå™¨\n    discoverer_path = models_path / \"discoverer_model.pt\"\n    torch.save(gan_trainer.generator.state_dict(), discoverer_path)\n    print(f\"âœ… Discoverer saved: {discoverer_path}\")\n    \n    # 2. ä¿å­˜åˆ¤åˆ«å™¨\n    ranker_path = models_path / \"ranker_model.pt\"\n    torch.save(gan_trainer.discriminator.state_dict(), ranker_path)\n    print(f\"âœ… Ranker saved: {ranker_path}\")\n    \n    # 3. ä¿å­˜å…ƒä¿¡æ¯\n    metadata = {\n        'description': 'GAN-RL Adversarial Learning - Production Models',\n        'training_date': datetime.now().isoformat(),\n        'generator_type': type(gan_trainer.generator).__name__,\n        'discriminator_type': type(gan_trainer.discriminator).__name__,\n        'device': str(gan_trainer.device),\n        'training_epochs': len(gan_trainer.training_stats.get('generator_rewards', [])),\n        'final_generator_reward': gan_trainer.training_stats.get('generator_rewards', [0])[-1] if gan_trainer.training_stats.get('generator_rewards') else 0,\n        'final_discriminator_loss': gan_trainer.training_stats.get('discriminator_losses', [0])[-1] if gan_trainer.training_stats.get('discriminator_losses') else 0,\n        'model_architecture': {\n            'generator': {\n                'max_path_length': getattr(gan_trainer.generator, 'max_path_length', 6),\n                'beam_width': getattr(gan_trainer.generator, 'beam_width', 5)\n            }\n        }\n    }\n    \n    metadata_path = models_path / \"model_metadata.json\"\n    with open(metadata_path, 'w', encoding='utf-8') as f:\n        json.dump(metadata, f, indent=2, ensure_ascii=False)\n    print(f\"ðŸ“‹ Metadata saved: {metadata_path}\")\n    \n    # 4. ä¿å­˜è®­ç»ƒåŽ†å²\n    training_history = {\n        'generator_rewards': gan_trainer.training_stats.get('generator_rewards', []),\n        'discriminator_losses': gan_trainer.training_stats.get('discriminator_losses', []),\n        'discriminator_accuracies': gan_trainer.training_stats.get('discriminator_accuracies', []),\n        'training_completed': datetime.now().isoformat()\n    }\n    \n    history_path = models_path / \"training_history.json\"\n    with open(history_path, 'w', encoding='utf-8') as f:\n        json.dump(training_history, f, indent=2, ensure_ascii=False)\n    print(f\"ðŸ“ˆ Training history saved: {history_path}\")\n    \n    print(f\"ðŸŽ‰ Production models saved successfully!\")\n    print(f\"ðŸ“ Models directory: {models_path.absolute()}\")\n    \n    return str(models_path)\n\ndef main():\n    \"\"\"æ¼”ç¤ºé«˜çº§æŽ¨ç†ç³»ç»Ÿ\"\"\"\n    print(\"ðŸš€ Advanced Inference System Demo\")\n    print(\"=\" * 50)\n    \n    # åˆå§‹åŒ–ç³»ç»Ÿ\n    system = AdvancedInferenceSystem()\n    \n    # åŠ è½½æ¨¡åž‹\n    if not system.load_production_models():\n        print(\"âŒ Failed to load production models. Please train models first.\")\n        print(\"ðŸ’¡ Run: python test_astar_generator.py\")\n        return\n    \n    # åŠ è½½æµ‹è¯•æ•°æ®\n    samples_file = \"selected_1hop_samples.json\"\n    if not Path(samples_file).exists():\n        print(f\"âŒ Test samples not found: {samples_file}\")\n        return\n    \n    samples = []\n    with open(samples_file, 'r', encoding='utf-8') as f:\n        for line in f:\n            if line.strip():\n                samples.append(json.loads(line.strip()))\n    \n    # è½¬æ¢ä¸ºæŸ¥è¯¢æ ¼å¼\n    queries = []\n    for sample in samples[:3]:  # æµ‹è¯•å‰3ä¸ª\n        queries.append({\n            'question': sample['question'],\n            'start_entity': sample['question_entity'],\n            'target_entities': set(sample['answer_entities'])\n        })\n    \n    # æ‰¹é‡æŽ¨ç†\n    results = system.batch_inference(queries, top_k=5)\n    \n    # æ˜¾ç¤ºç³»ç»Ÿç»Ÿè®¡\n    stats = system.get_system_stats()\n    print(f\"\\nðŸ“Š System Statistics:\")\n    for key, value in stats.items():\n        if isinstance(value, dict):\n            print(f\"  {key}:\")\n            for sub_key, sub_value in value.items():\n                print(f\"    {sub_key}: {sub_value}\")\n        else:\n            print(f\"  {key}: {value}\")\n\nif __name__ == \"__main__\":\n    main()