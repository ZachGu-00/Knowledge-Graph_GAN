"""
高级推理系统：生成-筛选 (Generate-and-Filter) 框架

场景二：双重保障推理系统
- Discoverer (生成器): "广撒网，找好鱼" - 生成Top-K候选路径
- Ranker (判别器): "精挑细选，找鱼王" - 为每条路径打出专业分数

优势：
1. 双重保障，提升精度：两阶段验证机制显著提升Hits@1
2. 置信度分数：Ranker输出可靠的confidence score (0-1)
3. 系统鲁棒性：Ranker能识别Discoverer的错误判断
"""

import sys
import torch
import json
import numpy as np
from typing import List, Tuple, Dict, Set, Optional
from pathlib import Path
from datetime import datetime

# 添加models路径
sys.path.append(str(Path(__file__).parent / "models" / "path_discover"))
sys.path.append(str(Path(__file__).parent / "models" / "path_ranker"))

from differentiable_path_generator_truly_fixed import DifferentiablePathGeneratorTrulyFixed
from enhanced_path_ranker import EnhancedPathRankerDiscriminator
from gan_rl_trainer import GANRLTrainer

class AdvancedInferenceSystem:
    """
    高级推理系统：双重保障的路径推理
    
    核心思想：
    1. 训练好的Discoverer = "路径发现专家"
    2. 训练好的Ranker = "路径鉴赏大师" 
    3. 两者配合 = 无敌组合
    """
    
    def __init__(self, models_dir: str = "checkpoints/production_models"):
        self.models_dir = Path(models_dir)
        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'
        
        self.discoverer = None  # 生成器：路径发现专家
        self.ranker = None      # 判别器：路径鉴赏大师
        
        # 推理统计
        self.inference_stats = {
            'total_queries': 0,
            'successful_queries': 0,
            'average_candidates': 0,
            'average_confidence': 0,
            'confidence_distribution': []
        }
    
    def load_production_models(self):
        """
        加载生产环境模型
        
        预期结构：
        checkpoints/production_models/
        ├── discoverer_model.pt      # 单独的生成器权重
        ├── ranker_model.pt          # 单独的判别器权重
        ├── model_metadata.json      # 模型元信息
        └── training_history.json    # 训练历史
        """
        print(f\"Loading production models from: {self.models_dir}\")\n        
        if not self.models_dir.exists():
            print(f\"❌ Models directory not found: {self.models_dir}\")\n            return False\n        \n        try:\n            # 1. 加载Discoverer (生成器)\n            discoverer_path = self.models_dir / \"discoverer_model.pt\"\n            if discoverer_path.exists():\n                self.discoverer = DifferentiablePathGeneratorTrulyFixed(\n                    entity_embedding_path=\"embeddings/entity_embeddings.pt\",\n                    max_path_length=6,\n                    beam_width=5\n                )\n                self.discoverer.load_state_dict(torch.load(discoverer_path, map_location=self.device))\n                self.discoverer.to(self.device)\n                self.discoverer.eval()\n                print(\"✅ Discoverer (生成器) loaded successfully\")\n            else:\n                print(f\"❌ Discoverer model not found: {discoverer_path}\")\n                return False\n            \n            # 2. 加载Ranker (判别器)\n            ranker_path = self.models_dir / \"ranker_model.pt\"\n            if ranker_path.exists():\n                self.ranker = EnhancedPathRankerDiscriminator(\n                    freeze_sbert=True,\n                    disable_pattern_memory=True\n                )\n                self.ranker.load_state_dict(torch.load(ranker_path, map_location=self.device))\n                self.ranker.to(self.device)\n                self.ranker.eval()\n                print(\"✅ Ranker (判别器) loaded successfully\")\n            else:\n                print(f\"❌ Ranker model not found: {ranker_path}\")\n                return False\n            \n            # 3. 加载模型元信息\n            metadata_path = self.models_dir / \"model_metadata.json\"\n            if metadata_path.exists():\n                with open(metadata_path, 'r', encoding='utf-8') as f:\n                    metadata = json.load(f)\n                print(f\"📋 Model Info: {metadata.get('description', 'N/A')}\")\n                print(f\"📅 Training Date: {metadata.get('training_date', 'N/A')}\")\n                print(f\"🏆 Performance: Hits@1={metadata.get('hits_at_1', 'N/A')}\")\n            \n            print(\"🎉 Production models loaded successfully!\")\n            return True\n            \n        except Exception as e:\n            print(f\"❌ Error loading models: {e}\")\n            return False\n    \n    def generate_candidate_paths(self, question: str, start_entity: str, \n                               target_entities: Set[str], top_k: int = 5) -> List[Tuple[List[str], float]]:\n        \"\"\"\n        阶段1：生成候选路径 (Discoverer的工作)\n        \n        Args:\n            question: 用户问题\n            start_entity: 起始实体\n            target_entities: 目标实体集合\n            top_k: 生成候选数量\n            \n        Returns:\n            List of (path, generator_score) tuples\n        \"\"\"\n        if self.discoverer is None:\n            raise ValueError(\"Discoverer not loaded. Call load_production_models() first.\")\n        \n        print(f\"🔍 Discoverer: Generating {top_k} candidate paths...\")\n        \n        try:\n            # 使用确定性模式生成多条路径\n            self.discoverer.eval()\n            generated_paths = self.discoverer.generate_paths(\n                question=question,\n                start_entity=start_entity,\n                target_entities=target_entities,\n                max_paths=top_k,\n                stochastic=False  # 确定性，但仍能生成多样化路径\n            )\n            \n            candidates = []\n            for path, score, _ in generated_paths:\n                if len(path) > 0:\n                    candidates.append((path, float(score)))\n            \n            print(f\"✅ Generated {len(candidates)} candidate paths\")\n            return candidates\n            \n        except Exception as e:\n            print(f\"❌ Discoverer error: {e}\")\n            return []\n    \n    def rank_and_filter_paths(self, question: str, candidates: List[Tuple[List[str], float]]) -> List[Tuple[List[str], float, float]]:\n        \"\"\"\n        阶段2：筛选与重排 (Ranker的工作)\n        \n        Args:\n            question: 用户问题\n            candidates: [(path, generator_score), ...]\n            \n        Returns:\n            List of (path, generator_score, ranker_confidence) tuples，按ranker分数降序排列\n        \"\"\"\n        if self.ranker is None:\n            raise ValueError(\"Ranker not loaded. Call load_production_models() first.\")\n        \n        if not candidates:\n            return []\n        \n        print(f\"🧠 Ranker: Evaluating {len(candidates)} candidates...\")\n        \n        try:\n            ranked_results = []\n            \n            for path, gen_score in candidates:\n                # 构造Ranker输入格式\n                final_entity = path[-1]\n                path_string = '.'.join(path)\n                path_data = [{'paths': {final_entity: [path_string]}}]\n                \n                # Ranker评分\n                with torch.no_grad():\n                    ranker_output = self.ranker([question], path_data, epoch=0)\n                    raw_score = float(ranker_output[0]['individual_scores'][0])\n                    confidence = float(torch.sigmoid(torch.tensor(raw_score)))  # 转为0-1置信度\n                \n                ranked_results.append((path, gen_score, confidence))\n            \n            # 按Ranker置信度降序排序\n            ranked_results.sort(key=lambda x: x[2], reverse=True)\n            \n            print(f\"✅ Ranker evaluation completed\")\n            return ranked_results\n            \n        except Exception as e:\n            print(f\"❌ Ranker error: {e}\")\n            return [(path, gen_score, 0.0) for path, gen_score in candidates]\n    \n    def inference(self, question: str, start_entity: str, target_entities: Set[str],\n                 top_k_candidates: int = 5, return_all_candidates: bool = False) -> Dict:\n        \"\"\"\n        完整推理流程：生成-筛选 (Generate-and-Filter)\n        \n        Args:\n            question: 用户问题\n            start_entity: 起始实体  \n            target_entities: 目标实体集合\n            top_k_candidates: 生成候选数量\n            return_all_candidates: 是否返回所有候选路径\n            \n        Returns:\n            {\n                'best_path': List[str],           # 最佳路径\n                'confidence': float,              # 置信度 (0-1)\n                'generator_score': float,         # 生成器分数\n                'all_candidates': List,           # 所有候选（可选）\n                'num_candidates': int,            # 候选数量\n                'inference_time': float           # 推理耗时\n            }\n        \"\"\"\n        start_time = datetime.now()\n        \n        print(f\"\\n🎯 Advanced Inference: {question}\")\n        print(f\"📍 Start: {start_entity}\")\n        print(f\"🎯 Targets: {list(target_entities)}\")\n        print(\"-\" * 60)\n        \n        # 阶段1：Discoverer生成候选\n        candidates = self.generate_candidate_paths(\n            question, start_entity, target_entities, top_k_candidates\n        )\n        \n        if not candidates:\n            return {\n                'best_path': [],\n                'confidence': 0.0,\n                'generator_score': 0.0,\n                'all_candidates': [],\n                'num_candidates': 0,\n                'inference_time': (datetime.now() - start_time).total_seconds(),\n                'status': 'no_candidates_generated'\n            }\n        \n        # 阶段2：Ranker筛选重排\n        ranked_candidates = self.rank_and_filter_paths(question, candidates)\n        \n        # 选择最佳路径（Ranker分数最高的）\n        best_path, best_gen_score, best_confidence = ranked_candidates[0]\n        \n        # 更新统计信息\n        self.inference_stats['total_queries'] += 1\n        if best_confidence > 0.5:  # 假设置信度>0.5为成功\n            self.inference_stats['successful_queries'] += 1\n        self.inference_stats['confidence_distribution'].append(best_confidence)\n        \n        inference_time = (datetime.now() - start_time).total_seconds()\n        \n        print(f\"\\n🏆 FINAL RESULT:\")\n        print(f\"📍 Best Path: {' -> '.join(best_path)}\")\n        print(f\"🎯 Target Hit: {'YES' if best_path[-1] in target_entities else 'NO'}\")\n        print(f\"📊 Generator Score: {best_gen_score:.4f}\")\n        print(f\"🧠 Ranker Confidence: {best_confidence:.4f} ({best_confidence*100:.1f}%)\")\n        print(f\"⏱️ Inference Time: {inference_time:.3f}s\")\n        \n        result = {\n            'best_path': best_path,\n            'confidence': best_confidence,\n            'generator_score': best_gen_score,\n            'num_candidates': len(candidates),\n            'inference_time': inference_time,\n            'target_hit': best_path[-1] in target_entities if best_path else False,\n            'status': 'success'\n        }\n        \n        if return_all_candidates:\n            result['all_candidates'] = [\n                {\n                    'path': path,\n                    'generator_score': gen_score,\n                    'ranker_confidence': confidence,\n                    'rank': i + 1\n                }\n                for i, (path, gen_score, confidence) in enumerate(ranked_candidates)\n            ]\n        \n        return result\n    \n    def batch_inference(self, queries: List[Dict], top_k: int = 5) -> List[Dict]:\n        \"\"\"\n        批量推理\n        \n        Args:\n            queries: [{'question': str, 'start_entity': str, 'target_entities': Set[str]}, ...]\n            \n        Returns:\n            List of inference results\n        \"\"\"\n        print(f\"\\n🚀 Batch Inference: {len(queries)} queries\")\n        print(\"=\" * 80)\n        \n        results = []\n        for i, query in enumerate(queries, 1):\n            print(f\"\\n[{i}/{len(queries)}] Processing query...\")\n            \n            result = self.inference(\n                question=query['question'],\n                start_entity=query['start_entity'],\n                target_entities=query['target_entities'],\n                top_k_candidates=top_k\n            )\n            \n            results.append(result)\n        \n        # 批量统计\n        successful = sum(1 for r in results if r['target_hit'])\n        avg_confidence = np.mean([r['confidence'] for r in results])\n        \n        print(f\"\\n📊 BATCH RESULTS:\")\n        print(f\"✅ Success Rate: {successful}/{len(queries)} ({successful/len(queries)*100:.1f}%)\")\n        print(f\"🧠 Average Confidence: {avg_confidence:.4f} ({avg_confidence*100:.1f}%)\")\n        \n        return results\n    \n    def get_system_stats(self) -> Dict:\n        \"\"\"获取系统统计信息\"\"\"\n        if self.inference_stats['total_queries'] == 0:\n            return {'message': 'No inference performed yet'}\n        \n        confidences = self.inference_stats['confidence_distribution']\n        \n        return {\n            'total_queries': self.inference_stats['total_queries'],\n            'success_rate': self.inference_stats['successful_queries'] / self.inference_stats['total_queries'],\n            'average_confidence': np.mean(confidences),\n            'confidence_std': np.std(confidences),\n            'confidence_distribution': {\n                'high (>0.8)': sum(1 for c in confidences if c > 0.8),\n                'medium (0.5-0.8)': sum(1 for c in confidences if 0.5 < c <= 0.8),\n                'low (<0.5)': sum(1 for c in confidences if c <= 0.5)\n            }\n        }\n\ndef save_production_models(gan_trainer: GANRLTrainer, models_dir: str = \"checkpoints/production_models\"):\n    \"\"\"\n    将训练好的GAN-RL模型保存为生产环境格式\n    \n    保存结构：\n    checkpoints/production_models/\n    ├── discoverer_model.pt      # 生成器权重\n    ├── ranker_model.pt          # 判别器权重  \n    ├── model_metadata.json      # 元信息\n    └── training_history.json    # 训练历史\n    \"\"\"\n    models_path = Path(models_dir)\n    models_path.mkdir(parents=True, exist_ok=True)\n    \n    print(f\"💾 Saving production models to: {models_path}\")\n    \n    # 1. 保存生成器\n    discoverer_path = models_path / \"discoverer_model.pt\"\n    torch.save(gan_trainer.generator.state_dict(), discoverer_path)\n    print(f\"✅ Discoverer saved: {discoverer_path}\")\n    \n    # 2. 保存判别器\n    ranker_path = models_path / \"ranker_model.pt\"\n    torch.save(gan_trainer.discriminator.state_dict(), ranker_path)\n    print(f\"✅ Ranker saved: {ranker_path}\")\n    \n    # 3. 保存元信息\n    metadata = {\n        'description': 'GAN-RL Adversarial Learning - Production Models',\n        'training_date': datetime.now().isoformat(),\n        'generator_type': type(gan_trainer.generator).__name__,\n        'discriminator_type': type(gan_trainer.discriminator).__name__,\n        'device': str(gan_trainer.device),\n        'training_epochs': len(gan_trainer.training_stats.get('generator_rewards', [])),\n        'final_generator_reward': gan_trainer.training_stats.get('generator_rewards', [0])[-1] if gan_trainer.training_stats.get('generator_rewards') else 0,\n        'final_discriminator_loss': gan_trainer.training_stats.get('discriminator_losses', [0])[-1] if gan_trainer.training_stats.get('discriminator_losses') else 0,\n        'model_architecture': {\n            'generator': {\n                'max_path_length': getattr(gan_trainer.generator, 'max_path_length', 6),\n                'beam_width': getattr(gan_trainer.generator, 'beam_width', 5)\n            }\n        }\n    }\n    \n    metadata_path = models_path / \"model_metadata.json\"\n    with open(metadata_path, 'w', encoding='utf-8') as f:\n        json.dump(metadata, f, indent=2, ensure_ascii=False)\n    print(f\"📋 Metadata saved: {metadata_path}\")\n    \n    # 4. 保存训练历史\n    training_history = {\n        'generator_rewards': gan_trainer.training_stats.get('generator_rewards', []),\n        'discriminator_losses': gan_trainer.training_stats.get('discriminator_losses', []),\n        'discriminator_accuracies': gan_trainer.training_stats.get('discriminator_accuracies', []),\n        'training_completed': datetime.now().isoformat()\n    }\n    \n    history_path = models_path / \"training_history.json\"\n    with open(history_path, 'w', encoding='utf-8') as f:\n        json.dump(training_history, f, indent=2, ensure_ascii=False)\n    print(f\"📈 Training history saved: {history_path}\")\n    \n    print(f\"🎉 Production models saved successfully!\")\n    print(f\"📁 Models directory: {models_path.absolute()}\")\n    \n    return str(models_path)\n\ndef main():\n    \"\"\"演示高级推理系统\"\"\"\n    print(\"🚀 Advanced Inference System Demo\")\n    print(\"=\" * 50)\n    \n    # 初始化系统\n    system = AdvancedInferenceSystem()\n    \n    # 加载模型\n    if not system.load_production_models():\n        print(\"❌ Failed to load production models. Please train models first.\")\n        print(\"💡 Run: python test_astar_generator.py\")\n        return\n    \n    # 加载测试数据\n    samples_file = \"selected_1hop_samples.json\"\n    if not Path(samples_file).exists():\n        print(f\"❌ Test samples not found: {samples_file}\")\n        return\n    \n    samples = []\n    with open(samples_file, 'r', encoding='utf-8') as f:\n        for line in f:\n            if line.strip():\n                samples.append(json.loads(line.strip()))\n    \n    # 转换为查询格式\n    queries = []\n    for sample in samples[:3]:  # 测试前3个\n        queries.append({\n            'question': sample['question'],\n            'start_entity': sample['question_entity'],\n            'target_entities': set(sample['answer_entities'])\n        })\n    \n    # 批量推理\n    results = system.batch_inference(queries, top_k=5)\n    \n    # 显示系统统计\n    stats = system.get_system_stats()\n    print(f\"\\n📊 System Statistics:\")\n    for key, value in stats.items():\n        if isinstance(value, dict):\n            print(f\"  {key}:\")\n            for sub_key, sub_value in value.items():\n                print(f\"    {sub_key}: {sub_value}\")\n        else:\n            print(f\"  {key}: {value}\")\n\nif __name__ == \"__main__\":\n    main()